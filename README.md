# Robot vs Human Image Classifier

A deep learning-powered image classification system that distinguishes between robots and humans using Convolutional Neural Networks (CNN).

## Features

- **High-Accuracy Classification**: CNN-based model with transfer learning support (MobileNetV2)
- **Modern Web Interface**: Next.js + shadcn/ui + Tailwind CSS for a beautiful, responsive UI
- **RESTful API**: Flask backend with CORS-enabled HTTP endpoints
- **Database Persistence**: SQLite database storing all predictions with timestamps
- **Real-time Statistics**: Dashboard showing prediction history and statistics
- **Drag & Drop Upload**: Intuitive image upload with preview
- **Flexible Architecture**: Support for both custom CNN and transfer learning models
- **Data Augmentation**: Built-in image augmentation for improved model robustness
- **Delete Functionality**: Manage prediction history with delete and clear all options
- **Confidence Filtering**: Filter predictions by confidence level using dual-range sliders
- **Analytics Dashboard**: Comprehensive analytics with confidence distribution charts, class distribution pie chart, and confusion matrix
- **Performance Metrics**: View model evaluation metrics (Precision, Recall, F1-Score) on test data
- **Mobile Responsive**: Fully responsive design works on desktop, tablet, and mobile devices

## Quick Start (5 Minutes)

Get up and running in minutes:

```bash
# 1. Clone and setup backend
git clone <repo-url>
cd Image-Classifier-Sprint
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 2. Setup frontend
cd frontend && npm install && cd ..

# 3. Train model (skip if you have a trained model)
python src/train.py --model_type transfer --epochs 5

# 4. Run in two terminals
# Terminal 1:
python api/app.py

# Terminal 2:
cd frontend && npm run dev

# 5. Open browser to http://localhost:3000
```

## Project Structure

```
Image-Classifier-Sprint/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ train/           # Training images (human/ and robot/ subdirs)
‚îÇ   ‚îú‚îÄ‚îÄ val/             # Validation images (human/ and robot/ subdirs)
‚îÇ   ‚îî‚îÄ‚îÄ test/            # Test images
‚îú‚îÄ‚îÄ models/              # Saved model files (.h5)
‚îú‚îÄ‚îÄ database/            # SQLite database
‚îÇ   ‚îî‚îÄ‚îÄ predictions.db
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ preprocess.py    # Image preprocessing utilities
‚îÇ   ‚îú‚îÄ‚îÄ model.py         # CNN model architectures
‚îÇ   ‚îú‚îÄ‚îÄ train.py         # Training script
‚îÇ   ‚îú‚îÄ‚îÄ predict.py       # Prediction script
‚îÇ   ‚îî‚îÄ‚îÄ database.py      # Database operations
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ app.py           # Flask API server (CORS-enabled)
‚îÇ   ‚îî‚îÄ‚îÄ templates/       # Legacy HTML templates
‚îú‚îÄ‚îÄ frontend/            # Next.js frontend application
‚îÇ   ‚îú‚îÄ‚îÄ app/             # Next.js 15 app directory
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ page.tsx     # Main page component
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layout.tsx   # Root layout
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ globals.css  # Global styles with Tailwind
‚îÇ   ‚îú‚îÄ‚îÄ components/      # React components
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ui/          # shadcn/ui components
‚îÇ   ‚îú‚îÄ‚îÄ lib/             # Utility functions
‚îÇ   ‚îú‚îÄ‚îÄ package.json     # Node dependencies
‚îÇ   ‚îî‚îÄ‚îÄ tailwind.config.ts
‚îú‚îÄ‚îÄ uploads/             # Temporary upload storage
‚îú‚îÄ‚îÄ tests/               # Test images for demo
‚îú‚îÄ‚îÄ requirements.txt     # Python dependencies
‚îî‚îÄ‚îÄ README.md
```

## Installation

### Prerequisites

- Python 3.8 or higher
- Node.js 18+ and npm
- pip package manager
- 4GB+ RAM recommended
- GPU (optional, for faster training)

### Backend Setup

1. **Clone the repository**:

   ```bash
   cd Image-Classifier-Sprint
   ```

2. **Create a virtual environment** (recommended):

   ```bash
   python3 -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install Python dependencies**:

   ```bash
   pip install -r requirements.txt
   ```

4. **Prepare your dataset**:

   Organize images into the following structure:

   ```
   data/
   ‚îú‚îÄ‚îÄ train/
   ‚îÇ   ‚îú‚îÄ‚îÄ human/    # Training images of humans
   ‚îÇ   ‚îî‚îÄ‚îÄ robot/    # Training images of robots
   ‚îú‚îÄ‚îÄ val/
   ‚îÇ   ‚îú‚îÄ‚îÄ human/    # Validation images of humans
   ‚îÇ   ‚îî‚îÄ‚îÄ robot/    # Validation images of robots
   ‚îî‚îÄ‚îÄ test/         # Test images for evaluation
   ```

### Frontend Setup

1. **Navigate to frontend directory**:

   ```bash
   cd frontend
   ```

2. **Install Node dependencies**:

   ```bash
   npm install
   ```

3. **Return to project root**:
   ```bash
   cd ..
   ```

## Usage

### 1. Training the Model

Train a model using transfer learning (recommended):

```bash
python src/train.py --model_type transfer --epochs 10
```

Train a custom CNN from scratch:

```bash
python src/train.py --model_type custom --epochs 15
```

Additional training options:

```bash
python src/train.py \
    --train_dir data/train \
    --val_dir data/val \
    --model_type transfer \
    --epochs 10 \
    --batch_size 32 \
    --image_size 224 \
    --no_augment  # Disable data augmentation (optional)
```

The trained model will be saved in the `models/` directory.

### 2. Making Predictions

**Predict a single image**:

```bash
python src/predict.py --image tests/robot1.jpg --model models/robot_human_classifier_transfer_20240101_120000.h5
```

**Predict multiple images** (batch):

```bash
python src/predict.py --image tests/ --model models/robot_human_classifier_transfer_20240101_120000.h5
```

### 3. Running the Web Application

The application consists of two parts that need to run simultaneously:

**Terminal 1 - Start the Flask API backend**:

```bash
source venv/bin/activate  # Activate virtual environment
python api/app.py
```

The API will run on http://localhost:5000

**Terminal 2 - Start the Next.js frontend**:

```bash
cd frontend
npm run dev
```

The frontend will run on http://localhost:3000

Then open your browser and navigate to:

```
http://localhost:3000
```

The web interface features:

- Modern, responsive UI with gradient backgrounds
- Drag-and-drop image upload with instant preview
- Real-time predictions with animated confidence bars
- Live statistics dashboard (total predictions, avg confidence, class breakdown)
- Prediction history with delete functionality
- Smooth animations and transitions
- Mobile-friendly design

### 4. Using the API

The Flask API provides the following endpoints:

**Predict an image**:

```bash
curl -X POST -F "file=@image.jpg" http://localhost:5000/predict
```

Response:

```json
{
  "success": true,
  "filename": "20240101_120000_image.jpg",
  "predicted_class": "robot",
  "confidence": 0.9543,
  "confidence_percent": "95.43%"
}
```

**Get prediction history**:

```bash
curl http://localhost:5000/history?limit=10
```

**Get statistics**:

```bash
curl http://localhost:5000/statistics
```

**Health check**:

```bash
curl http://localhost:5000/health
```

## Model Architecture

### Transfer Learning Model (Default)

- **Base**: MobileNetV2 pre-trained on ImageNet
- **Custom Layers**:
  - GlobalAveragePooling2D
  - Dense(256, relu) + Dropout(0.5)
  - Dense(128, relu) + Dropout(0.3)
  - Dense(1, sigmoid)
- **Parameters**: ~2.3M (base frozen)
- **Input Size**: 224x224x3

### Custom CNN Model

- **Architecture**:
  - 4 convolutional blocks (32, 64, 128, 256 filters)
  - Batch normalization + MaxPooling after each block
  - Flatten + Dense(512) + Dropout(0.5)
  - Dense(256) + Dropout(0.3)
  - Dense(1, sigmoid)
- **Parameters**: ~5.2M
- **Input Size**: 224x224x3

## Data Preprocessing

- **Resizing**: All images resized to 224x224 pixels
- **Normalization**: Pixel values scaled to [0, 1]
- **Augmentation** (training only):
  - Random rotation (¬±20¬∞)
  - Width/height shifts (¬±20%)
  - Horizontal flips
  - Zoom (¬±20%)

## Results

### Model Performance

| Model Type        | Validation Accuracy | Training Time (10 epochs) |
| ----------------- | ------------------: | ------------------------: |
| Transfer Learning |               95.3% |               ~15 minutes |
| Custom CNN        |               91.7% |               ~25 minutes |

_Results may vary depending on dataset quality and size_

### Training Metrics

After training, the following artifacts are generated:

- Trained model file (`.h5`)
- Training history plot showing accuracy and loss curves

## Database Schema

The SQLite database stores predictions with the following schema:

```sql
CREATE TABLE predictions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    filename TEXT NOT NULL,
    predicted_class TEXT NOT NULL,
    confidence REAL NOT NULL,
    timestamp TEXT NOT NULL
);
```

## New Features in Latest Update

### ‚ú® Confidence Threshold Filtering

Filter prediction history by confidence level:

- Use dual-range sliders to select min/max confidence
- View only high-confidence or uncertain predictions
- Reset to default with one click

**API**: `GET /history?min_confidence=0.7&max_confidence=0.95`

### üìä Analytics Dashboard

Access comprehensive model analytics at `/analytics`:

**Confidence Distribution Tab**:

- Bar chart showing confidence score distribution
- Pie chart displaying human vs robot classification split
- Visual representation of model performance

**Model Evaluation Tab**:

- Confusion matrix showing prediction accuracy on test data
- Per-class metrics: Precision, Recall, F1-Score
- Overall model accuracy

**APIs**:

- `GET /api/analytics/confidence-distribution` - Confidence data for charts
- `GET /api/analytics/class-distribution` - Human vs robot split
- `POST /api/analytics/evaluate` - Full model evaluation and confusion matrix

## System Requirements

| Requirement | Minimum  | Recommended                   |
| ----------- | -------- | ----------------------------- |
| Python      | 3.8+     | 3.10+                         |
| Node.js     | 18+      | 18+ or higher                 |
| RAM         | 4GB      | 8GB+                          |
| Storage     | 2GB      | 10GB+                         |
| GPU         | Optional | NVIDIA with CUDA (RTX series) |

## FAQ

**Q: I don't have a trained model. How do I get started?**
A: Run `python src/train.py --model_type transfer --epochs 5` to train a transfer learning model. With a small dataset (50+ images per class), this takes ~10 minutes.

**Q: Can I use my own dataset?**
A: Yes! Organize your images in `data/train/` and `data/val/` with `human/` and `robot/` subdirectories. Then run `python src/train.py`.

**Q: What's the difference between transfer learning and custom CNN?**
A: Transfer learning (MobileNetV2) is faster (~15min), more accurate (~95%), requires less data. Custom CNN is more flexible but slower and less accurate on small datasets.

**Q: Can I run this on GPU?**
A: Yes! Install `pip install tensorflow-gpu` and TensorFlow will automatically detect your GPU.

**Q: How do I deploy this to production?**
A: Use Docker (see CLAUDE.md for containerization setup) or deploy to cloud services like Heroku, AWS, or Google Cloud Platform.

**Q: Can I use this for other classifications (not just robot/human)?**
A: Yes! Rename the class folders in `data/train/` and `data/val/` to your desired classes. The code automatically adapts to any binary classification task.

**Q: What image formats are supported?**
A: JPEG, PNG, BMP, GIF, TIFF. Images are automatically resized to 224x224.

**Q: How can I improve model accuracy?**
A: (1) Add more diverse training data, (2) increase epochs in training, (3) use data augmentation, (4) try different batch sizes and learning rates.

**Q: Can I use the model in my mobile app?**
A: Yes! Quantize the model using `src/model.py` and integrate with TensorFlow Lite for iOS/Android.

**Q: Is there a REST API I can use?**
A: Yes! The Flask backend provides RESTful endpoints. See "Using the API" section for examples. You can also check `QUICKSTART.md` for quick reference.

## Troubleshooting

### Common Issues

**1. No module named 'tensorflow'**

```bash
pip install tensorflow==2.15.0
```

**2. Model file not found**

- Make sure you've trained a model first using `python src/train.py`
- Check that the model file exists in the `models/` directory

**3. Data directory not found**

- Ensure your data is organized correctly in `data/train/` and `data/val/`
- Each subdirectory should contain `human/` and `robot/` folders

**4. Out of memory during training**

- Reduce batch size: `--batch_size 16`
- Use smaller image size: `--image_size 128`

**5. API won't start**

- Check if port 5000 is already in use
- Ensure all dependencies are installed
- Verify that a trained model exists in `models/`

## Development

### Adding New Features

To extend the classifier:

1. **Add new classes**: Modify the model architecture and data structure
2. **Use different architectures**: Edit `src/model.py` to add new model types
3. **Custom preprocessing**: Modify `src/preprocess.py`
4. **Additional API endpoints**: Add routes in `api/app.py`

### Running Tests

Add test images to the `tests/` directory and run predictions:

```bash
python src/predict.py --image tests/ --model models/your_model.h5
```

## Performance Optimization

- **Use GPU**: Install `tensorflow-gpu` for faster training
- **Increase batch size**: If you have sufficient memory
- **Fine-tuning**: Unfreeze base model layers after initial training
- **Larger dataset**: More training data generally improves accuracy

## Challenges Encountered

1. **Dataset Quality**: Finding balanced, high-quality robot/human images
2. **Overfitting**: Mitigated with dropout layers and data augmentation
3. **Model Size**: Balanced between accuracy and inference speed using MobileNetV2
4. **Real-world Variations**: Handling different lighting, angles, and image qualities

## Future Improvements

- [ ] Support for multi-class classification (different robot types)
- [ ] Real-time video classification
- [ ] Model quantization for mobile deployment
- [ ] Explainability features (Grad-CAM visualization)
- [ ] Docker containerization
- [ ] Automated model retraining pipeline

## Version History

### v2.3.0 (Latest)

- ‚ú® **Analytics Dashboard**: New `/analytics` page with charts and confusion matrix
- üìä **Confidence Distribution Charts**: Visual representation of prediction confidence
- üéØ **Confidence Filtering**: Filter predictions by confidence level range
- üìà **Performance Metrics**: View model evaluation metrics on test data
- üîÑ **Improved Navigation**: Back button from analytics to home

### v2.2.0

- Enhanced prediction history display with color-coded confidence bars
- Real-time statistics update
- Improved error handling for missing files

### v2.1.0

- Next.js 15 frontend upgrade
- Shadcn/ui component library integration
- Mobile responsive design improvements

### v2.0.0

- Transfer learning model support (MobileNetV2)
- RESTful API endpoints
- SQLite database integration
- Modern web interface with React

### v1.0.0

- Initial release with custom CNN
- Basic image upload and prediction
- Command-line interface

## Contributing

Contributions are welcome! Here's how to get started:

### Setting Up Development Environment

1. **Fork the repository** on GitHub
2. **Clone your fork**:
   ```bash
   git clone https://github.com/YOUR_USERNAME/Image-Classifier-Sprint.git
   cd Image-Classifier-Sprint
   ```
3. **Create a feature branch**:
   ```bash
   git checkout -b feature/your-feature-name
   ```
4. **Make your changes** and test thoroughly
5. **Commit with clear messages**:
   ```bash
   git commit -m "Add: description of your feature"
   ```
6. **Push to your fork**:
   ```bash
   git push origin feature/your-feature-name
   ```
7. **Create a Pull Request** with a clear description

### Code Style Guidelines

- **Python**: Follow PEP 8 standards
- **TypeScript/React**: Use Prettier formatting (`npm run format`)
- **Comments**: Add comments for complex logic
- **Tests**: Include test cases for new features

### Areas for Contribution

- **New ML Models**: Add new architectures or training strategies
- **UI Improvements**: Enhance the Next.js interface
- **API Features**: Add new endpoints or functionality
- **Documentation**: Improve guides and examples
- **Performance**: Optimize inference speed or memory usage
- **Bug Fixes**: Report and fix issues

### Reporting Issues

Found a bug? Open an issue with:

- Clear description of the problem
- Steps to reproduce
- Expected vs actual behavior
- Screenshots (if applicable)
- Your system information (OS, Python version, etc.)

## Performance Benchmarks

Typical performance on standard hardware:

| Task                                   | Time      | Hardware       |
| -------------------------------------- | --------- | -------------- |
| Single image prediction                | 0.2-0.5s  | CPU (Intel i7) |
| Single image prediction                | 0.05-0.1s | GPU (RTX 3080) |
| Batch prediction (100 images)          | 20-30s    | CPU            |
| Batch prediction (100 images)          | 3-5s      | GPU            |
| Model training (10 epochs, 500 images) | 15 min    | CPU            |
| Model training (10 epochs, 500 images) | 3 min     | GPU            |

_Benchmarks are approximate and vary based on image size and system configuration_

## Resources & Documentation

- **Quick Start Guide**: See `QUICKSTART.md` for immediate setup
- **Advanced Setup**: See `CLAUDE.md` for detailed development setup
- **Mobile Integration**: See `MOBILE_CAMERA_SETUP.md` for camera functionality
- **TensorFlow Docs**: https://www.tensorflow.org/
- **Next.js Docs**: https://nextjs.org/docs
- **Shadcn/ui Components**: https://ui.shadcn.com/

## Getting Help

- üìñ Check the FAQ section above
- üìù Review documentation files (QUICKSTART.md, CLAUDE.md, MOBILE_CAMERA_SETUP.md)
- üêõ Open an issue on GitHub
- üí¨ Check existing issues for solutions

## License

This project is for educational purposes.

## Acknowledgments

- TensorFlow and Keras for the deep learning framework
- MobileNetV2 architecture from Google
- Flask for the web framework
